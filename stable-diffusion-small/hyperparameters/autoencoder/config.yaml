inference:
  image_width: 512
  latent_dim: 4
  latent_width: 64

model:
  target: models.autoencoder.VAutoEncoder
  params:
    lr: 0.5
    beta_scale: 0.75
    encoder_config:
      target: modules.autoencoder.encoder.VEncoder
      params:
        base_channels: 192
        num_groups: 32
        z_scale_factor: 0.18215
    decoder_config:
      target: modules.autoencoder.decoder.VDecoder
      params:
        base_channels: 192
        num_groups: 32
        z_scale_factor: 0.18215

data:
  target: modules.data.autoencoder.AutoEncoderDataModule
  params:
    data_path: "Ryan-sjtu/celebahq-caption" 
    seed: 52    
    batch_size: 8                  
    image_size: 512                   
    num_workers: 10                   
    buffer_size: 512                
    train_val_split: 0.05                        
    preprocess_batch_fn: "preprocess_celebahq_caption"
    collate_fn: "collate_celebahq_caption"  
    